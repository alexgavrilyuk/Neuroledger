/**
 * @fileoverview This service manages the agent execution loop.
 * It dynamically loads available tools, prepares context using AgentContextService,
 * orchestrates the interaction with the LLM (streaming), executes tool calls,
 * manages intermediate state, handles retries, and updates the database record.
 * The primary export is the `runAgent` function.
 */

const logger = require('../../shared/utils/logger');
const PromptHistory = require('./prompt.model');
// Removed getIO import - using sendEventCallback directly
const { streamLLMReasoningResponse } = require('./prompt.service');
const { toolDefinitions } = require('./tools/tool.definitions');
const AgentContextService = require('./agentContext.service');
const { summarizeToolResult, formatToolResultForLLM } = require('./agent.utils');
const path = require('path');
const fs = require('fs');

// Constants
const MAX_AGENT_ITERATIONS = 10;
const MAX_TOOL_RETRIES = 1;

// --- Dynamic Tool Loading ---
/**
 * @description Loads tool implementation functions dynamically from the ./tools directory.
 * Skips tool.definitions.js and hidden files.
 * Maps filenames to tool names (e.g., answer_user.js -> _answerUserTool).
 * @type {Object<string, Function>}
 */
const toolsDirectory = path.join(__dirname, 'tools');
const toolImplementations = {};

try {
    fs.readdirSync(toolsDirectory)
        .filter(file => file.endsWith('.js') && file !== 'tool.definitions.js' && !file.startsWith('.')) // Exclude hidden files
        .forEach(file => {
            const toolName = path.basename(file, '.js');
            // Adjust tool name if filename differs (e.g., answer_user.js -> _answerUserTool)
            const adjustedToolName = toolName === 'answer_user' ? '_answerUserTool' : toolName;
            try {
                const toolModule = require(path.join(toolsDirectory, file));
                if (typeof toolModule === 'function') {
                    toolImplementations[adjustedToolName] = toolModule;
                    logger.info(`[Agent] Loaded tool: ${adjustedToolName} from ${file}`);
                } else {
                     logger.warn(`[Agent] Failed to load tool ${adjustedToolName}: Module from ${file} does not export a function.`);
                }
            } catch (error) {
                logger.error(`[Agent] Failed to load tool ${adjustedToolName} from ${file}: ${error.message}`, { stack: error.stack });
            }
        });
} catch (error) {
     logger.error(`[Agent] Failed to read tools directory ${toolsDirectory}: ${error.message}`, { stack: error.stack });
     // Potentially throw here if tools are critical? Or proceed without tools?
}
logger.info(`[Agent] Available tools: ${Object.keys(toolImplementations).join(', ')}`);
// --- End Tool Loading ---

/**
 * Orchestrates the agent's reasoning loop with streaming capabilities.
 * Handles fetching context, interacting with the LLM, executing tools, managing state,
 * and streaming results back via a callback.
 */
class AgentExecutor {
    /**
     * @typedef {object} AgentStep
     * @property {string} tool - Name of the tool executed (or signal like '_answerUserTool').
     * @property {object} args - Arguments passed to the tool.
     * @property {string} resultSummary - A concise summary of the tool's result or error.
     * @property {any} [result] - The actual result payload from a successful tool execution (stored for context).
     * @property {string} [error] - Error message if the tool execution failed.
     * @property {number} attempt - The attempt number for this step (handles retries).
     */

    /**
     * @typedef {object} IntermediateResults
     * @property {object<string, object>} datasetSchemas - Map of datasetId to schema info.
     * @property {object<string, object>} datasetSamples - Map of datasetId to sample data.
     * @property {object<string, Array<object>>} parsedData - Map of datasetId to fully parsed data array.
     * @property {any} analysisResult - Result from the last successful execute_analysis_code call.
     * @property {string|null} generatedReportCode - React code generated by generate_report_code.
     * @property {any} previousAnalysisResult - Analysis result carried over from a previous turn.
     * @property {string|null} previousGeneratedCode - Generated code carried over from a previous turn.
     */

    /**
     * @typedef {object} TurnContext
     * @property {string} originalQuery - The user's query for this turn.
     * @property {AgentStep[]} steps - An array tracking the agent's actions this turn.
     * @property {IntermediateResults} intermediateResults - Holds data needed across steps within the turn.
     * @property {string} userContext - Context string related to the user's settings/profile.
     * @property {string} teamContext - Context string related to the team's settings/profile.
     * @property {Array<{role: string, content: string}>} fullChatHistory - Formatted chat history for the LLM.
     * @property {string|null} finalAnswer - The final text answer determined by the agent.
     * @property {string|null} error - Any critical error message encountered during the turn.
     * @property {object<string, number>} toolErrorCounts - Tracks retry attempts for each tool.
     */

    /**
     * Initializes the AgentExecutor for a single agent turn.
     * @param {string} userId - The ID of the user initiating the request.
     * @param {string | null} teamId - The ID of the team context (or null).
     * @param {string} sessionId - The ID of the chat session.
     * @param {string} aiMessagePlaceholderId - The MongoDB ObjectId of the PromptHistory record for this turn.
     * @param {function(string, object): void} sendEventCallback - Function to stream events (e.g., llm_chunk, agent_status) back to the caller.
     * @param {any} [initialPreviousAnalysisData=null] - Analysis data from a previous turn (optional).
     * @param {string} [initialPreviousGeneratedCode=null] - Generated code from a previous turn (optional).
     */
    constructor(userId, teamId, sessionId, aiMessagePlaceholderId, sendEventCallback, initialPreviousAnalysisData = null, initialPreviousGeneratedCode = null) {
        this.userId = userId;
        this.teamId = teamId;
        this.sessionId = sessionId;
        this.aiMessagePlaceholderId = aiMessagePlaceholderId;
        this.sendEventCallback = sendEventCallback;
        /** @type {AgentContextService} */
        this.contextService = new AgentContextService(userId, teamId, sessionId);

        // Initialize turn-specific context
        /** @type {TurnContext} */
        this.turnContext = {
            originalQuery: '',
            steps: [], // Tracks tool calls and results for this turn { tool, args, resultSummary, result?, error?, attempt }
            intermediateResults: {
                datasetSchemas: {}, // { [datasetId]: schemaInfo }
                datasetSamples: {}, // { [datasetId]: { totalRows, sampleRows } }
                parsedData: {},     // { [datasetId]: Array<object> } - Store actual parsed data
                analysisResult: null, // Result from execute_analysis_code
                generatedReportCode: null, // Result from generate_report_code
                previousAnalysisResult: initialPreviousAnalysisData, // Carry over from previous turns if provided
                previousGeneratedCode: initialPreviousGeneratedCode,
            },
            userContext: '',
            teamContext: '',
            fullChatHistory: [], // Formatted history for LLM [{ role, content }]
            finalAnswer: null,
            error: null,
            toolErrorCounts: {}, // { [toolName]: count }
        };

        /** @type {string[]} */
        this.knownToolNames = Object.keys(toolImplementations);
        logger.debug(`[AgentExecutor ${sessionId}] Initialized.`);
    }

    // --- Streaming & Status Updates ---
    /**
     * Sends low-level streaming events (LLM chunks, final results) via the provided callback.
     * Handles potential errors in the callback function itself.
     * @private
     * @param {string} eventType - The type of event (e.g., 'llm_chunk', 'agent_status', 'final_result').
     * @param {object} data - The payload for the event.
     */
    _sendStreamEvent(eventType, data) {
        if (typeof this.sendEventCallback === 'function') {
            try {
                this.sendEventCallback(eventType, data);
            } catch (callbackError) {
                 logger.error(`[AgentExecutor ${this.sessionId}] Error executing sendEventCallback for event ${eventType}: ${callbackError.message}`, { stack: callbackError.stack });
            }
        } else {
            logger.warn(`[AgentExecutor ${this.sessionId}] sendEventCallback is not defined. Cannot send stream event ${eventType}.`);
        }
    }

    /**
     * Emits higher-level agent status updates (thinking, using_tool, tool_result, error, final_answer)
     * via the `_sendStreamEvent` method, bundling common context.
     * Uses the specific `eventName` as the SSE event type for frontend compatibility.
     * @private
     * @param {string} eventName - The specific agent status event name (e.g., 'agent:thinking').
     * @param {object} payload - Additional data specific to the event.
     */
    _emitAgentStatus(eventName, payload) {
            const eventPayload = {
                messageId: this.aiMessagePlaceholderId,
                sessionId: this.sessionId,
            userId: this.userId, // Include userId for potential client-side filtering/routing
                ...payload,
            };
        // Send the specific eventName as the SSE event type
        this._sendStreamEvent(eventName, eventPayload);
        logger.debug(`[AgentExecutor ${this.sessionId}] Emitted Agent Status SSE Event: ${eventName}`, payload); // Log specific payload
    }

    // --- Data Access Callback --- 
    /**
     * Callback function provided to tools (specifically `execute_analysis_code`)
     * allowing them to retrieve previously parsed data stored in the turn context.
     * @private
     * @param {string} datasetId - The ID of the dataset whose parsed data is needed.
     * @returns {Promise<Array<object>|null>} The parsed data array or null if not found.
     */
    async _getParsedDataForTool(datasetId) {
        logger.debug(`[AgentExecutor ${this.sessionId}] Tool requesting parsed data for dataset: ${datasetId}`);
        const data = this.turnContext.intermediateResults.parsedData[datasetId];
        if (!data) {
             logger.warn(`[AgentExecutor ${this.sessionId}] Parsed data for dataset ${datasetId} not found in intermediate results.`);
             return null;
        }
        return data;
    }

    // --- Main Execution Loop ---
    /**
     * Executes the primary agent reasoning loop for a single turn.
     * 1. Prepares context (history, datasets, user/team info).
     * 2. Iteratively calls the LLM (streaming):
     *    - Prepares LLM context including previous steps/results.
     *    - Streams LLM response chunks back.
     *    - Parses tool calls or final answer signals from the stream or complete response.
     * 3. Executes Tools:
     *    - Calls the appropriate tool implementation.
     *    - Handles retries on failure.
     *    - Stores results in intermediate state.
     *    - Emits tool usage and result status events.
     * 4. Finalizes:
     *    - Breaks loop on final answer, max iterations, or critical error.
     *    - Updates the PromptHistory record with the final status and results.
     *    - Sends a final result event.
     *
     * @async
     * @param {string} userMessage - The user's current message/query for this turn.
     * @param {Array<string>} sessionDatasetIds - Array of dataset IDs available in the current chat session.
     * @returns {Promise<{status: 'completed'|'error', aiResponseText?: string, aiGeneratedCode?: string, error?: string}>} Final status object summarizing the turn's outcome.
     */
    async runAgentLoopWithStreaming(userMessage, sessionDatasetIds = []) {
        logger.info(`[AgentExecutor ${this.sessionId}] Starting streaming loop for user ${this.userId}. Query: "${userMessage.substring(0, 50)}..."`);
        this.turnContext.originalQuery = userMessage;
        this.turnContext.toolErrorCounts = {}; // Reset errors
        let iterations = 0;

        try {
            // 0. Initial Setup & Emit Thinking Status
            this._emitAgentStatus('agent:thinking', {});

            // 1. Prepare Initial Context Concurrently
            const initialContextPromise = this.contextService.getInitialUserTeamContext();
            const datasetContextPromise = this.contextService.preloadDatasetContext(sessionDatasetIds);
            const historyPromise = this.contextService.prepareChatHistoryAndArtifacts(this.aiMessagePlaceholderId);

            // Use Promise.allSettled to handle potential errors in context fetching gracefully
            const [initialCtxResult, datasetCtxResult, historyResultSettled] = await Promise.allSettled([
                initialContextPromise,
                datasetContextPromise,
                historyPromise
            ]);

            // Process results, logging errors but continuing if possible
            if (initialCtxResult.status === 'fulfilled') {
                this.turnContext.userContext = initialCtxResult.value.userContext;
                this.turnContext.teamContext = initialCtxResult.value.teamContext;
            } else {
                logger.error(`[AgentExecutor ${this.sessionId}] Failed to get initial user/team context: ${initialCtxResult.reason}`);
            }

            if (datasetCtxResult.status === 'fulfilled') {
                this.turnContext.intermediateResults.datasetSchemas = datasetCtxResult.value.datasetSchemas;
                this.turnContext.intermediateResults.datasetSamples = datasetCtxResult.value.datasetSamples;
                    } else {
                 logger.error(`[AgentExecutor ${this.sessionId}] Failed to preload dataset context: ${datasetCtxResult.reason}`);
            }

            if (historyResultSettled.status === 'fulfilled') {
                const historyResult = historyResultSettled.value;
                this.turnContext.fullChatHistory = historyResult.fullChatHistory;
                // Carry over previous artifacts only if not already set by constructor
                if (this.turnContext.intermediateResults.previousAnalysisResult === null) {
                    this.turnContext.intermediateResults.previousAnalysisResult = historyResult.previousAnalysisResult;
                }
                if (this.turnContext.intermediateResults.previousGeneratedCode === null) {
                    this.turnContext.intermediateResults.previousGeneratedCode = historyResult.previousGeneratedCode;
                }
                     } else {
                 logger.error(`[AgentExecutor ${this.sessionId}] Failed to prepare chat history: ${historyResultSettled.reason}`);
                 // Continue with empty history? Decide based on requirements.
                 this.turnContext.fullChatHistory = [];
            }

            logger.debug(`[AgentExecutor ${this.sessionId}] Context prepared. History: ${this.turnContext.fullChatHistory.length}. Schemas: ${Object.keys(this.turnContext.intermediateResults.datasetSchemas).length}. Samples: ${Object.keys(this.turnContext.intermediateResults.datasetSamples).length}.`);

            // --- Main Reasoning Loop ---
            let currentLLMResponse = '';
            let parsedToolCallFromStream = null; // Store tool call detected mid-stream
            let llmFinished = false;
            let finalAnswerFromLLM = null; // Store the final answer text if LLM signals it directly

            while (iterations < MAX_AGENT_ITERATIONS) {
                iterations++;
                logger.info(`[AgentExecutor ${this.sessionId}] Iteration ${iterations}`);
                currentLLMResponse = '';
                parsedToolCallFromStream = null;
                llmFinished = false;
                finalAnswerFromLLM = null; // Reset for this iteration

                // 2. Prepare LLM Context for this iteration
                const llmContext = this._prepareLLMContextForStream();

                // 3. Stream LLM Response & Parse Tool Calls/Final Answer Signal
                await streamLLMReasoningResponse(
                    llmContext,
                    async (eventType, data) => {
                        switch (eventType) {
                            case 'llm_chunk':
                                currentLLMResponse += data.chunk;
                                // Send chunk to client immediately
                                this._sendStreamEvent('llm_chunk', { chunk: data.chunk });
                                break;
                            case 'token':
                                // Add to accumulating response
                                currentLLMResponse += data.content;
                                // Send token to client immediately
                                this._sendStreamEvent('token', { content: data.content });
                                break;
                            case 'tool_call':
                                // Tool call structure detected by the streaming service
                                parsedToolCallFromStream = { tool: data.tool, args: data.args };
                                logger.info(`[AgentExecutor ${this.sessionId}] Tool call parsed during stream: ${data.tool}`);
                                // Emit status *now* that we know a tool is likely being used
                                this._emitAgentStatus('agent:using_tool', { toolName: data.tool, args: data.args });
                                // Don't break; allow LLM to potentially stream thoughts after the call
                                break;
                             case 'final_answer':
                                 // The prompt service detected a signal that this is the final answer
                                 finalAnswerFromLLM = data.text || currentLLMResponse.trim(); // Use provided text or accumulated chunks
                                 logger.info(`[AgentExecutor ${this.sessionId}] Final answer signal received from LLM stream.`);
                                 // Could potentially break here if we don't care about post-answer thoughts
                                 break;
                            case 'finish':
                                llmFinished = true;
                                logger.debug(`[AgentExecutor ${this.sessionId}] LLM stream finished naturally. Reason: ${data.finishReason || 'unspecified'}`);
                                break;
                            case 'completed':
                                // Stream completed successfully
                                logger.debug(`[AgentExecutor ${this.sessionId}] LLM stream completed event received.`);
                                break;
                            case 'error':
                                logger.error(`[AgentExecutor ${this.sessionId}] LLM streaming error: ${data.error}`);
                                throw new Error(`LLM streaming error: ${data.error}`); // Propagate error
                        }
                    }
                );

                // 4. Process LLM Output: Decide Action
                let action = null;
                let isFinalAnswer = false;

                // ADDED: Log the raw LLM response content
                logger.debug(`[AgentExecutor ${this.sessionId}] Raw LLM response (truncated): "${currentLLMResponse.substring(0, 1000)}${currentLLMResponse.length > 1000 ? '...' : ''}"`);

                if (finalAnswerFromLLM !== null) {
                     // Explicit final answer signal received during streaming
                     action = { tool: '_answerUserTool', args: { textResponse: finalAnswerFromLLM }};
                     isFinalAnswer = true;
                     this.turnContext.finalAnswer = finalAnswerFromLLM;
                     logger.debug(`[AgentExecutor ${this.sessionId}] Using explicit final answer signal from stream: "${finalAnswerFromLLM.substring(0, 200)}..."`);
                } else if (parsedToolCallFromStream) {
                    // Tool call parsed during streaming takes precedence
                    action = parsedToolCallFromStream;
                    isFinalAnswer = false;
                    logger.debug(`[AgentExecutor ${this.sessionId}] Using tool call parsed during stream: ${action.tool}`);
                } else if (llmFinished) {
                     // LLM finished without explicit tool call or final answer signal during stream.
                     // Parse the *complete* response to check for a formatted tool call or treat as answer.
                     logger.debug(`[AgentExecutor ${this.sessionId}] Attempting to parse complete LLM response...`);
                     const parseResult = this._parseCompleteLLMResponse(currentLLMResponse);
                     logger.debug(`[AgentExecutor ${this.sessionId}] Parse result: tool=${parseResult.tool}, isFinalAnswer=${parseResult.isFinalAnswer}, textResponse length=${parseResult.textResponse?.length || 0}`);
                     action = { tool: parseResult.tool, args: parseResult.args };
                     isFinalAnswer = parseResult.isFinalAnswer;
                     this.turnContext.finalAnswer = parseResult.textResponse; // Store potential final answer
                     } else {
                     // Stream ended unexpectedly (e.g., error handled above, or timeout?)
                     logger.warn(`[AgentExecutor ${this.sessionId}] LLM stream ended without finish event or final answer signal.`);
                     logger.debug(`[AgentExecutor ${this.sessionId}] Using raw response as final answer: "${currentLLMResponse.substring(0, 200)}..."`);
                     action = { tool: '_answerUserTool', args: { textResponse: currentLLMResponse.trim() } };
                     isFinalAnswer = true;
                     this.turnContext.finalAnswer = currentLLMResponse.trim();
                }

                // 5. Execute Action or Finish
                if (action.tool === '_answerUserTool' || isFinalAnswer) {
                    logger.info(`[AgentExecutor ${this.sessionId}] Agent loop ending with final answer.`);
                    // Ensure final answer text is captured
                    if (!this.turnContext.finalAnswer) {
                        this.turnContext.finalAnswer = action.args?.textResponse || currentLLMResponse.trim() || "I apologize, but I couldn't formulate a response.";
                        logger.warn(`[AgentExecutor ${this.sessionId}] Final answer text was missing, using fallback.`);
                    }
                    this.turnContext.steps.push({ tool: '_answerUserTool', args: { textResponse: this.turnContext.finalAnswer }, resultSummary: 'Final answer provided.' });
                    this._emitAgentStatus('agent:final_answer', { text: this.turnContext.finalAnswer });
                    break; // Exit loop
                }

                if (action.tool && toolImplementations[action.tool]) {
                    logger.info(`[AgentExecutor ${this.sessionId}] Executing Tool: ${action.tool}`);
                    const currentStepIndex = this.turnContext.steps.length;

                    // --- ADDED: Inject generated analysis code before execution --- 
                    let finalArgs = { ...action.args }; // Clone args
                    if (action.tool === 'execute_analysis_code' && this.turnContext.intermediateResults.generatedAnalysisCode) {
                        logger.info(`[AgentExecutor ${this.sessionId}] Substituting generated code into execute_analysis_code arguments.`);
                        finalArgs.code = this.turnContext.intermediateResults.generatedAnalysisCode;
                        // Optional: Log snippet of injected code for verification
                        // logger.debug(`[AgentExecutor ${this.sessionId}] Injected code snippet (first 500): ${finalArgs.code.substring(0, 500)}`);
                    } else if (action.tool === 'execute_analysis_code') {
                        logger.warn(`[AgentExecutor ${this.sessionId}] execute_analysis_code requested, but no generated code found in context! Using LLM provided code (likely placeholder).`);
                    }
                    // --- END ADDED --- 

                    // Ensure step is added *before* execution for potential retries
                    this.turnContext.steps.push({ 
                        tool: action.tool, 
                        args: finalArgs, // Use finalArgs with potentially substituted code
                        resultSummary: 'Executing tool...', 
                        attempt: 1
                    });
                    // Emit status only if not already emitted during stream parsing
                    if (!parsedToolCallFromStream) {
                        // Use finalArgs for the emitted event too
                        this._emitAgentStatus('agent:using_tool', { toolName: action.tool, args: finalArgs });
                    }

                    // Pass finalArgs to the execution method
                    let toolResult = await this._executeTool(action.tool, finalArgs);
                    let resultSummary = summarizeToolResult(toolResult); // Use utility

                    // --- Retry Logic ---
                    if (toolResult.error && (this.turnContext.toolErrorCounts[action.tool] || 0) < MAX_TOOL_RETRIES) {
                         const retryCount = (this.turnContext.toolErrorCounts[action.tool] || 0) + 1;
                         this.turnContext.toolErrorCounts[action.tool] = retryCount;
                        logger.warn(`[AgentExecutor ${this.sessionId}] Tool ${action.tool} failed. Retrying (${retryCount}/${MAX_TOOL_RETRIES}). Error: ${toolResult.error}`);

                        // Update step for retry attempt
                        this.turnContext.steps[currentStepIndex].resultSummary = `Error (Attempt ${retryCount}): ${toolResult.error}. Retrying...`;
                        this.turnContext.steps[currentStepIndex].error = toolResult.error; // Store error on step
                              this.turnContext.steps[currentStepIndex].attempt = retryCount + 1; 
                        this._emitAgentStatus('agent:tool_result', { toolName: action.tool, resultSummary: this.turnContext.steps[currentStepIndex].resultSummary, error: toolResult.error });

                        // Re-emit using_tool for clarity
                         this._emitAgentStatus('agent:using_tool', { toolName: action.tool, args: action.args }); 
                        toolResult = await this._executeTool(action.tool, action.args); // Re-execute
                        resultSummary = summarizeToolResult(toolResult); // Summarize new result
                    }
                    // --- End Retry Logic ---

                    // Update step with final result/error of this attempt
                    this.turnContext.steps[currentStepIndex].resultSummary = resultSummary;
                         if (toolResult.error) {
                        this.turnContext.steps[currentStepIndex].error = toolResult.error;
                         } else {
                         this.turnContext.steps[currentStepIndex].result = toolResult.result; // Store success result on step if needed later
                    }

                    this._emitAgentStatus('agent:tool_result', { toolName: action.tool, resultSummary, error: toolResult.error });

                    // Store intermediate results explicitly if successful
                    if (!toolResult.error) {
                        this._storeIntermediateResult(action.tool, toolResult);
                    }

                    // Check for critical errors after potential retry
                    if (toolResult.error && (action.tool === 'execute_analysis_code')) {
                        logger.error(`[AgentExecutor ${this.sessionId}] CRITICAL ERROR during code execution after retries: ${toolResult.error}. Terminating loop.`);
                        this.turnContext.error = `Code Execution Failed: ${resultSummary}`;
                        throw new Error(this.turnContext.error); // Throw to be caught by outer handler
                    }
                    // Loop continues for next LLM call...
                    
                } else { 
                    // LLM finished but action was not final answer and not a known tool
                    logger.error(`[AgentExecutor ${this.sessionId}] LLM response yielded unknown tool: ${action.tool}. Ending loop.`);
                    this.turnContext.finalAnswer = `I encountered an issue understanding the next step (unknown tool: ${action.tool}). Please try rephrasing your request.`;
                     this.turnContext.error = `Unknown tool requested: ${action.tool}`;
                    this.turnContext.steps.push({ tool: '_unknown', args: action.args || {}, resultSummary: this.turnContext.error });
                    break; // Exit loop with error state
                }
            } // End while loop

            // --- Loop Finished ---
            if (iterations >= MAX_AGENT_ITERATIONS && !this.turnContext.finalAnswer) {
                logger.warn(`[AgentExecutor ${this.sessionId}] Agent reached maximum iterations.`);
                this.turnContext.finalAnswer = "I apologize, but I couldn't complete the request within the allowed steps. The query might be too complex or I got stuck in a loop.";
                this.turnContext.steps.push({ tool: '_maxIterations', args: {}, resultSummary: 'Reached max iterations.' });
                // Fall through to update record and return gracefully
            }

            // If loop somehow finished without error but also without a final answer text
            if (!this.turnContext.finalAnswer && !this.turnContext.error) {
                logger.error(`[AgentExecutor ${this.sessionId}] Loop finished unexpectedly without a final answer or error state.`);
                this.turnContext.error = 'Agent loop finished without final answer';
                this.turnContext.finalAnswer = "I encountered an unexpected internal issue and could not complete the request.";
                 // This indicates a logic error, throw to ensure it's captured as an error
                throw new Error(this.turnContext.error);
            }

            // 6. Finalize: Update PromptHistory record (even if loop ended with error message in finalAnswer)
            const finalStatus = this.turnContext.error ? 'error' : 'completed';
            await this._updatePromptHistoryRecord(
                finalStatus,
                this.turnContext.finalAnswer, // Use the determined final answer
                this.turnContext.error, // Log specific error if one occurred
                this.turnContext.intermediateResults.generatedReportCode,
                this.turnContext.intermediateResults.analysisResult
            );

            logger.info(`[AgentExecutor ${this.sessionId}] Agent loop finished with status: ${finalStatus}.`);
            // Send final result event - REMOVED as frontend expects specific agent:final_answer and end events
            // this._sendStreamEvent('final_result', { ... }); 

            return { 
                status: finalStatus,
                aiResponseText: this.turnContext.finalAnswer,
                aiGeneratedCode: this.turnContext.intermediateResults.generatedReportCode,
                error: this.turnContext.error
            };

        } catch (error) {
            // Catch errors from within the loop (e.g., LLM stream error, critical tool error)
            logger.error(`[AgentExecutor ${this.sessionId}] Unhandled error during agent execution: ${error.message}`, { stack: error.stack });
            const errorMessage = this.turnContext.error || error.message || 'Unknown agent error';
            this.turnContext.error = errorMessage; // Ensure error is stored in context

            // Emit error status and update history record
            this._emitAgentStatus('agent:error', { error: errorMessage });
            try {
                await this._updatePromptHistoryRecord('error', null, errorMessage, null, null);
            } catch (updateError) {
                logger.error(`[AgentExecutor ${this.sessionId}] Failed to update prompt history with error status after catching loop error: ${updateError.message}`);
            }
             // Send final error result event
             this._sendStreamEvent('final_result', {
                 status: 'error',
                 error: errorMessage,
                 sessionId: this.sessionId,
                 messageId: this.aiMessagePlaceholderId
             });
            return { status: 'error', error: errorMessage };
        }
    }

    // --- LLM Response Parsing --- 
    /**
     * Parses the complete LLM response text when the stream finishes, *if* no specific
     * tool call or final answer signal was detected during the stream itself.
     * Attempts to extract a JSON tool call; otherwise treats the text as a final answer.
     * @private
     * @param {string} responseText - The complete text response accumulated from the LLM stream.
     * @returns {{tool: string, args: object, isFinalAnswer: boolean, textResponse: string|null}} Parsed action details.
     */
    _parseCompleteLLMResponse(responseText) {
        const trimmedResponse = responseText?.trim() || '';
        const defaultAnswer = { tool: '_answerUserTool', args: { textResponse: trimmedResponse }, isFinalAnswer: true, textResponse: trimmedResponse };

        if (!trimmedResponse) {
             logger.debug(`[AgentExecutor ${this.sessionId}] Complete LLM response is empty. Treating as final answer.`);
            return defaultAnswer;
        }

        // ADDED: Log the attempt to parse structured JSON
        logger.debug(`[AgentExecutor ${this.sessionId}] Attempting to extract JSON from response of length ${trimmedResponse.length}`);
        
        // Attempt to parse structured JSON (e.g., tool call)
        // Regex to find JSON object optionally enclosed in markdown fences
        const jsonRegex = /^```(?:json)?\s*(\{[^]*?\})\s*```$|^(\{[^]*?\})$/m; // Use [^]*? for non-greedy multi-line content
        const jsonMatch = trimmedResponse.match(jsonRegex);

        if (jsonMatch) {
            const potentialJson = jsonMatch[1] || jsonMatch[2];
            if (potentialJson) {
                // ADDED: Log the extracted potential JSON
                logger.debug(`[AgentExecutor ${this.sessionId}] Found potential JSON (first 500 chars): ${potentialJson.substring(0, 500)}${potentialJson.length > 500 ? '...' : ''}`);
                
                try {
                    // Basic sanitization might be needed here if JSON is complex (e.g., nested strings with quotes)
                    const parsed = JSON.parse(potentialJson);
                    
                    // ADDED: Log the successfully parsed JSON
                    logger.debug(`[AgentExecutor ${this.sessionId}] Successfully parsed JSON, checking structure. Found keys: ${Object.keys(parsed).join(', ')}`);

                    // Validate structure for tool call
                    if (parsed && typeof parsed.tool === 'string' && typeof parsed.args === 'object' && parsed.args !== null) {
                        if (this.knownToolNames.includes(parsed.tool)) {
                            logger.debug(`[AgentExecutor ${this.sessionId}] Parsed tool call from complete response: ${parsed.tool}`);
                             // Handle _answerUserTool specifically if called via JSON
                            if (parsed.tool === '_answerUserTool') {
                                 const textArg = parsed.args.textResponse;
                                if (typeof textArg === 'string' && textArg.trim() !== '') {
                                     return { tool: parsed.tool, args: parsed.args, isFinalAnswer: true, textResponse: textArg.trim() };
                                } else {
                                     logger.warn(`[AgentExecutor ${this.sessionId}] _answerUserTool in JSON lacks textResponse, using raw response.`);
                                     return defaultAnswer; // Fallback to treating raw response as answer
                                }
                            }
                            // Valid tool call found
                            return { tool: parsed.tool, args: parsed.args, isFinalAnswer: false, textResponse: null };
                        } else {
                            logger.warn(`[AgentExecutor ${this.sessionId}] Parsed JSON tool is unknown: ${parsed.tool}. Treating as final answer.`);
                            // Fall through to default answer
                        }
                    } else {
                        logger.warn(`[AgentExecutor ${this.sessionId}] Parsed JSON doesn't match expected tool structure. Treating as final answer.`);
                        // ADDED: Log details about why the structure was invalid
                        if (!parsed) {
                            logger.debug(`[AgentExecutor ${this.sessionId}] Parsed result is null or undefined`);
                        } else {
                            logger.debug(`[AgentExecutor ${this.sessionId}] Structure validation failed: tool is ${typeof parsed.tool}, args is ${typeof parsed.args}`);
                        }
                        // Fall through to default answer
                    }
                } catch (e) {
                    logger.warn(`[AgentExecutor ${this.sessionId}] Failed to parse JSON from complete response: ${e.message}. Content: ${potentialJson.substring(0, 200)}... Treating as final answer.`);
                    // Fall through to default answer
                }
            }
        } else {
            // ADDED: Log when no JSON pattern is found
            logger.debug(`[AgentExecutor ${this.sessionId}] No JSON pattern found in response. First 100 chars: ${trimmedResponse.substring(0, 100)}...`);
        }

        // No valid JSON tool call found, treat the entire response as the final answer.
        logger.debug(`[AgentExecutor ${this.sessionId}] Complete LLM response treated as final answer text.`);
        return defaultAnswer;
    }


    // --- Context Preparation --- 
    /**
     * Prepares the comprehensive context object required by the `streamLLMReasoningResponse` service call.
     * Gathers history, tool definitions, formatted results from previous steps in *this turn*,
     * user/team context, dataset info, and previous turn artifacts.
     * @private
     * @returns {object} Context object structured for the LLM prompt service.
     */
    _prepareLLMContextForStream() {
        // Summarize previous analysis result if available
        let previousAnalysisResultSummary = null;
        if (this.turnContext.intermediateResults.previousAnalysisResult) {
            try {
                // Provide a concise summary, avoiding large data structures
                const summary = JSON.stringify(this.turnContext.intermediateResults.previousAnalysisResult);
                previousAnalysisResultSummary = `Analysis results from a previous turn are available: ${summary.substring(0, 150)}${summary.length > 150 ? '...' : ''}`;
            } catch {
                previousAnalysisResultSummary = "Analysis results from a previous turn are available.";
            }
        }

        // Format results from tools executed *in this turn* for the next LLM call
        const formattedToolResults = this.turnContext.steps
            // Include only steps that are actual tool executions (not placeholders or final answer)
            .filter(step => step.tool !== '_answerUserTool' && step.resultSummary !== 'Executing tool...')
            .map(step => {
                // Use the utility function to format the result/error stored on the step object
                // Assumes _executeTool and retry logic store result/error on the step
                 const toolResultObject = { result: step.result, error: step.error };
                 // Append args to the result object so formatToolResultForLLM knows the context
                 // toolResultObject.args = step.args; // May not be needed by formatter
                 return formatToolResultForLLM(step.tool, toolResultObject);
            });

        return {
            // Identifiers
            userId: this.userId,
            sessionId: this.sessionId,

            // Core context
            originalQuery: this.turnContext.originalQuery,
            history: this.turnContext.fullChatHistory, // Use pre-fetched, formatted history
            availableTools: toolDefinitions, // Use imported definitions

            // Context from current turn state
            currentTurnSteps: this.turnContext.steps.map(s => ({ // Provide a summary of steps taken
                 tool: s.tool,
                 args: s.args, // Keep args for context
                 summary: s.resultSummary,
                 attempt: s.attempt
             })),
             formattedToolResults: formattedToolResults, // Pass formatted results from previous steps *in this turn*

            // Context from previous turns / datasets
            userContext: this.turnContext.userContext,
            teamContext: this.turnContext.teamContext,
            previousAnalysisResultSummary: previousAnalysisResultSummary,
            hasPreviousGeneratedCode: !!this.turnContext.intermediateResults.previousGeneratedCode,
            datasetSchemas: this.turnContext.intermediateResults.datasetSchemas,
            datasetSamples: this.turnContext.intermediateResults.datasetSamples,

             // Analysis result from *this turn* (e.g., for report generation prompt)
            currentAnalysisResult: this.turnContext.intermediateResults.analysisResult,
        };
    }

     // --- Intermediate State Management ---
    /**
     * Stores the successful result from a tool execution into the `turnContext.intermediateResults`.
     * This allows subsequent steps or tools (like `generate_report_code`) to access necessary data
     * (e.g., parsed data, analysis results).
     * @private
     * @param {string} toolName - The name of the tool that successfully executed.
     * @param {object} toolResult - The successful result object from the tool execution ({status: 'success', result: ..., args: ...}).
     */
    _storeIntermediateResult(toolName, toolResult) {
         // Ensure we only store successful results
         if (toolResult.error || toolResult.status !== 'success' || toolResult.result === undefined) {
             return;
         }

         const resultData = toolResult.result;
         const args = toolResult.args || {}; // Get args passed back from _executeTool

         try {
            switch (toolName) {
                case 'parse_csv_data':
                    // Expects { parsedData: Array<object>, rowCount: number } in resultData
                    if (resultData.parsedData && args.dataset_id) {
                        const datasetId = args.dataset_id;
                        this.turnContext.intermediateResults.parsedData[datasetId] = resultData.parsedData;
                        logger.info(`[AgentExecutor ${this.sessionId}] Stored parsed data for dataset ${datasetId} (${resultData.rowCount} rows).`);
            } else {
                        logger.warn(`[AgentExecutor ${this.sessionId}] parse_csv_data success result missing parsedData or dataset_id in args. Result:`, resultData, 'Args:', args);
                    }
                    break;
                case 'execute_analysis_code':
                    this.turnContext.intermediateResults.analysisResult = resultData;
                    logger.info(`[AgentExecutor ${this.sessionId}] Stored analysis execution result.`);
                    break;
                case 'generate_analysis_code':
                    if (resultData.code) {
                        this.turnContext.intermediateResults.generatedAnalysisCode = resultData.code;
                        logger.info(`[AgentExecutor ${this.sessionId}] Stored generated analysis code (length: ${resultData.code.length}).`);
            } else {
                        logger.warn(`[AgentExecutor ${this.sessionId}] generate_analysis_code success result missing code.`);
                    }
                    break;
                case 'generate_report_code':
                    if (resultData.react_code) {
                        this.turnContext.intermediateResults.generatedReportCode = resultData.react_code;
                        logger.info(`[AgentExecutor ${this.sessionId}] Stored generated React report code.`);
                } else {
                        logger.warn(`[AgentExecutor ${this.sessionId}] generate_report_code success result missing react_code.`);
                    }
                    break;
                // --- Add cases for other tools if their results need explicit storage ---
                // case 'get_dataset_schema':
                //    // Schemas are already stored during initial context prep if successful
                //    break;
                // case 'list_datasets':
                //    // Result is usually just informational for the LLM in the next step
                //    break;
                // case 'generate_analysis_code':
                //    // The generated code is immediately used by execute_analysis_code,
                //    // no need to store it long-term in intermediateResults unless specifically required elsewhere.
                //    break;
                default:
                    logger.debug(`[AgentExecutor ${this.sessionId}] No specific intermediate storage action defined for tool: ${toolName}`);
            }
         } catch (storageError) {
              logger.error(`[AgentExecutor ${this.sessionId}] Error storing intermediate result for tool ${toolName}: ${storageError.message}`, { data: resultData });
         }
     }

    // --- Tool Execution --- 
    /**
     * Dynamically loads and executes the requested tool function.
     * Passes necessary context (userId, sessionId, schemas, analysis results, callbacks) to the tool.
     * Handles basic validation of the tool's return structure.
     * @private
     * @param {string} toolName - The name of the tool to execute (must be a key in `toolImplementations`).
     * @param {object} args - The arguments object for the tool, provided by the LLM.
     * @returns {Promise<object>} The result object from the tool execution, including the original `args` for context.
     *                          Expected structure: {status: 'success'|'error', result?: any, error?: string, logs?: string[], args: object}.
     */
    async _executeTool(toolName, args) {
        const toolFunction = toolImplementations[toolName];
        if (!toolFunction) {
            logger.error(`[AgentExecutor ${this.sessionId}] Attempted to call unknown or unloaded tool: ${toolName}`);
            return { status: 'error', error: `Unknown tool: ${toolName}`, args };
        }

        logger.debug(`[AgentExecutor ${this.sessionId}] Preparing to execute tool: ${toolName}`, { args });

        try {
            // Prepare the context object to pass to the tool function
            const toolContext = {
                userId: this.userId,
                teamId: this.teamId,
                sessionId: this.sessionId,
                // Provide access to relevant parts of the turn context if needed by tools
                datasetSchemas: this.turnContext.intermediateResults.datasetSchemas,
                analysisResult: this.turnContext.intermediateResults.analysisResult,
                // Provide callback for tools needing data managed by orchestrator
                getParsedDataCallback: toolName === 'execute_analysis_code'
                    ? this._getParsedDataForTool.bind(this)
                    : undefined, // Only provide if needed
            };

            // Execute the tool function
            const toolResult = await toolFunction(args, toolContext);

            // Validate tool result structure (optional but good practice)
            if (typeof toolResult !== 'object' || !toolResult.status) {
                 logger.error(`[AgentExecutor ${this.sessionId}] Tool ${toolName} returned invalid result structure:`, toolResult);
                 return { status: 'error', error: `Tool ${toolName} returned an invalid result.`, args };
            }

            // Pass back the original args along with the result for context
            return { ...toolResult, args };

        } catch (error) {
            // Catch unexpected errors *within* the tool's execution
            logger.error(`[AgentExecutor ${this.sessionId}] Uncaught error during execution of tool ${toolName}: ${error.message}`, { stack: error.stack, toolArgs: args });
                return {
                 status: 'error',
                 error: `Tool execution failed unexpectedly: ${error.message}`,
                 args
            };
        }
    }

    // --- Database Update --- 
    /**
     * Updates the corresponding PromptHistory record in MongoDB with the final outcome of the agent turn.
     * Records the final status, response text, error message, generated code, analysis data, and steps taken.
     * Handles potential errors during the database update gracefully.
     * @private
     * @param {string} status - Final status: 'completed' or 'error'.
     * @param {string|null} [aiResponseText=null] - Final AI text response.
     * @param {string|null} [errorMessage=null] - Error message if status is 'error'.
     * @param {string|null} [aiGeneratedCode=null] - Generated React report code, if any.
     * @param {any|null} [analysisData=null] - Final analysis result data from `execute_analysis_code`, if any.
     */
    async _updatePromptHistoryRecord(status, aiResponseText = null, errorMessage = null, aiGeneratedCode = null, analysisData = null) {
        if (!this.aiMessagePlaceholderId) {
            logger.error(`[AgentExecutor ${this.sessionId}] Cannot update prompt history: aiMessagePlaceholderId is missing.`);
            // Cannot proceed without the ID
            return;
        }
        try {
            const updateData = {
                status: status,
                completedAt: new Date(),
                // Store a snapshot of the steps taken during this turn
                steps: this.turnContext.steps.map(s => ({
                    tool: s.tool,
                    args: s.args, // Consider censoring sensitive args if necessary
                    resultSummary: s.resultSummary,
                    error: s.error, // Include error message if step failed
                    attempt: s.attempt
                 })),
            };

            // Add fields conditionally
            if (aiResponseText !== null) updateData.aiResponseText = aiResponseText;
            // Use the specific error message if provided, otherwise use the general turn error
            if (errorMessage !== null || this.turnContext.error) updateData.errorMessage = errorMessage || this.turnContext.error;
            if (aiGeneratedCode !== null) updateData.aiGeneratedCode = aiGeneratedCode;
            // Store the final analysis result associated with this report/response
            if (analysisData !== null) updateData.reportAnalysisData = analysisData;

            const updatedRecord = await PromptHistory.findByIdAndUpdate(
                this.aiMessagePlaceholderId,
                { $set: updateData },
                { new: true } // Options: return the updated document
            ).lean(); // Use lean for performance if full Mongoose object isn't needed after update

            if (!updatedRecord) {
                // This is concerning - the placeholder ID should exist
                logger.error(`[AgentExecutor ${this.sessionId}] CRITICAL: Could not find PromptHistory record ${this.aiMessagePlaceholderId} to update.`);
            } else {
                logger.info(`[AgentExecutor ${this.sessionId}] Updated PromptHistory record ${this.aiMessagePlaceholderId} with final status: ${status}`);
            }
        } catch (error) {
            // Log error but don't let DB update failure stop the agent response flow
            logger.error(`[AgentExecutor ${this.sessionId}] Failed to update prompt history record ${this.aiMessagePlaceholderId}: ${error.message}`, { stack: error.stack });
        }
    }

} // End class AgentExecutor


// --- Exported Runner Function ---

/**
 * Main exported function to initiate and run the agent for a single user message turn.
 * Handles instantiation of the AgentExecutor and invoking its main streaming loop.
 * Performs basic validation on essential input parameters.
 * 
 * This function is intended to be called by higher-level services like `chat.service` or `chat.taskHandler`.
 *
 * @async
 * @param {object} params - Parameters required for the agent run.
 * @param {string} params.userId - ID of the user initiating the chat turn.
 * @param {string|null} params.teamId - ID of the relevant team, if applicable.
 * @param {string} params.sessionId - ID of the current chat session.
 * @param {string} params.aiMessagePlaceholderId - MongoDB ObjectId of the PromptHistory document placeholder for the AI's response.
 * @param {function(string, object): void} params.sendEventCallback - The callback function used to stream events back (e.g., to a WebSocket handler).
 * @param {string} params.userMessage - The raw text of the user's message.
 * @param {Array<string>} params.sessionDatasetIds - An array of dataset IDs accessible within this session.
 * @param {any} [params.initialPreviousAnalysisData] - Optional: Analysis data result from a previous turn to provide context.
 * @param {string} [params.initialPreviousGeneratedCode] - Optional: Generated code from a previous turn to provide context.
 * @returns {Promise<{status: 'completed'|'error', aiResponseText?: string, aiGeneratedCode?: string, error?: string}>} A promise resolving to the final status object summarizing the turn's outcome.
 */
async function runAgent(params) {
     const {
         userId,
         teamId,
         sessionId,
         aiMessagePlaceholderId,
         sendEventCallback, // Function to stream events back
         userMessage,
         sessionDatasetIds,
         initialPreviousAnalysisData,
         initialPreviousGeneratedCode
      } = params;

     // Basic validation
     if (!userId || !sessionId || !aiMessagePlaceholderId || typeof sendEventCallback !== 'function' || typeof userMessage !== 'string') {
         const errorMsg = 'Agent initialization failed: Missing or invalid required parameters.';
         logger.error(`[runAgent ${sessionId}] ${errorMsg}`, { userId, sessionId, aiMessagePlaceholderId: !!aiMessagePlaceholderId, hasCallback: typeof sendEventCallback === 'function', hasMessage: typeof userMessage === 'string' });
         // Attempt to send an error event if possible
         if (typeof sendEventCallback === 'function' && sessionId && aiMessagePlaceholderId) {
             sendEventCallback('agent_status', { eventName: 'agent:error', payload: { error: errorMsg, sessionId, messageId: aiMessagePlaceholderId } });
             sendEventCallback('final_result', { status: 'error', error: errorMsg, sessionId, messageId: aiMessagePlaceholderId });
         }
          // Update history if possible
         if (aiMessagePlaceholderId) {
             try {
                await PromptHistory.findByIdAndUpdate(aiMessagePlaceholderId, { $set: { status: 'error', errorMessage: errorMsg, completedAt: new Date() }});
             } catch(e) { logger.error(`[runAgent ${sessionId}] Failed to update history on init error`, e); }
         }
         return { status: 'error', error: errorMsg };
     }

     logger.info(`[runAgent ${sessionId}] Instantiating AgentExecutor for User ${userId}.`);
     const executor = new AgentExecutor(
         userId,
         teamId,
         sessionId,
         aiMessagePlaceholderId,
         sendEventCallback,
         initialPreviousAnalysisData,
         initialPreviousGeneratedCode
     );

     // Execute the main loop
     return await executor.runAgentLoopWithStreaming(userMessage || '', sessionDatasetIds || []);
}

module.exports = { runAgent }; // Export only the runner function
